{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRL via Apprenticeship Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- https://github.com/Farama-Foundation/HighwayEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "from matplotlib import pyplot as plt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the highway environment with configurations\n",
    "config = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"TimeToCollision\",\n",
    "        \"horizon\": 10\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "        \"longitudinal\": True,\n",
    "        \"lateral\": True\n",
    "    },\n",
    "    \"duration\": 40,\n",
    "    \"lanes_count\": 2,\n",
    "    \"vehicles_density\": 1.0,\n",
    "    \"collision_reward\": -1,\n",
    "    \"right_lane_reward\": 0.1,\n",
    "    \"high_speed_reward\": 0.4,\n",
    "    \"reward_speed_range\": [20, 30],\n",
    "    \"normalize_reward\": True\n",
    "}\n",
    "\n",
    "env = gym.make('highway-v0', render_mode='rgb_array', config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': {'lateral': True,\n",
      "            'longitudinal': True,\n",
      "            'type': 'DiscreteMetaAction'},\n",
      " 'centering_position': [0.3, 0.5],\n",
      " 'collision_reward': -1,\n",
      " 'controlled_vehicles': 1,\n",
      " 'duration': 40,\n",
      " 'ego_spacing': 2,\n",
      " 'high_speed_reward': 0.4,\n",
      " 'initial_lane_id': None,\n",
      " 'lane_change_reward': 0,\n",
      " 'lanes_count': 2,\n",
      " 'manual_control': False,\n",
      " 'normalize_reward': True,\n",
      " 'observation': {'horizon': 10, 'type': 'TimeToCollision'},\n",
      " 'offroad_terminal': False,\n",
      " 'offscreen_rendering': False,\n",
      " 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
      " 'policy_frequency': 1,\n",
      " 'real_time_rendering': False,\n",
      " 'render_agent': True,\n",
      " 'reward_speed_range': [20, 30],\n",
      " 'right_lane_reward': 0.1,\n",
      " 'scaling': 5.5,\n",
      " 'screen_height': 150,\n",
      " 'screen_width': 600,\n",
      " 'show_trajectories': False,\n",
      " 'simulation_frequency': 15,\n",
      " 'vehicles_count': 50,\n",
      " 'vehicles_density': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(env.unwrapped.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to finite MDP\n",
    "env.reset()\n",
    "base_env = env.unwrapped\n",
    "mdp = base_env.to_finite_mdp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0.0, 1.0, (3, 3, 10), float32)\n"
     ]
    }
   ],
   "source": [
    "# print the observation space\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Num | Observation Dimension | Meaning | Length | Min | Max |\n",
    "|-----|------------------------|---------|---------|-----|-----|\n",
    "| 0 | Ego‐speed channels | Predictions at V discrete ego‐speeds (e.g. low/med/high m/s) | 3 | 0.0 | 1.0 |\n",
    "| 1 | Lane channels | L lanes around the ego‐vehicle (left, current, right) | 3 | 0.0 | 1.0 |\n",
    "| 2 | Time-to-collision bins (horizon) | H discretized future time steps for collision prediction | 10 | 0.0 | 1.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "# print the action space\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type: Discrete(5)\n",
    "\n",
    "Num | Action\n",
    "--- | ---\n",
    "0 | Lane Left\n",
    "1 | Idle\n",
    "2 | Lane Right\n",
    "3 | Faster\n",
    "4 | Slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'LANE_LEFT', 1: 'IDLE', 2: 'LANE_RIGHT', 3: 'FASTER', 4: 'SLOWER'}\n"
     ]
    }
   ],
   "source": [
    "# Get all possible actions\n",
    "ACTIONS_ALL = base_env.action_type.actions\n",
    "print(ACTIONS_ALL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
